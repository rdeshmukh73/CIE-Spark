{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f568c68",
   "metadata": {},
   "source": [
    "### Multi-turn chat evaluation for every pitch deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6557df43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai import chats\n",
    "import time\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43681a29",
   "metadata": {},
   "source": [
    "### TIPSC Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb402024",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIPSC_FEW_SHOT_EXAMPLES = f\"\"\"\n",
    "Example 1 - \n",
    "Pitch Statement:\n",
    "\"An AI-powered tool that detects early signs of diabetic foot ulcers using smartphone images, helping rural healthcare \n",
    "workers intervene before complications arise.\"\n",
    "\n",
    "TIPSC Review:\n",
    "Timely: Rising diabetes cases in rural areas make early detection critical. (Score: 5)\n",
    "Important: Addresses a major healthcare gap affecting millions. (Score: 5)\n",
    "Profitable: Strong market through health-tech startups and public health programs. (Score: 4)\n",
    "Solvable: Feasible with current AI imaging and mobile tech. (Score: 5)\n",
    "Contextual: Team has medical + AI expertise with NGO partnerships. (Score: 5)\n",
    "\n",
    "Overall Assessment: Excellent (95%)\n",
    "Brief Justification: The problem is urgent, large-scale, and solvable with current technology. \n",
    "The team’s alignment with healthcare stakeholders strengthens contextual fit and market potential.\n",
    "\n",
    "Example 2 -\n",
    "Pitch Statement:\n",
    "\"A wearable hydration tracker that reminds users to drink water based on real-time sweat analysis and weather conditions.\"\n",
    "\n",
    "TIPSC Review:\n",
    "Timely: Wellness tech is growing, though hydration-specific solutions are not urgent. (Score: 4)\n",
    "Important: Moderate market among fitness and sports users. (Score: 4)\n",
    "Profitable: Viable as a premium product but niche appeal. (Score: 4)\n",
    "Solvable: Current sensors and IoT make it achievable. (Score: 5)\n",
    "Contextual: Team has IoT experience but limited market understanding. (Score: 3)\n",
    "\n",
    "Overall Assessment: Good (80%)\n",
    "Brief Justification: A relevant and buildable solution with moderate market potential; success depends on positioning \n",
    "and user adoption beyond enthusiasts.\n",
    "\n",
    "Example 3 - \n",
    "Pitch Statement:\n",
    "\"A desktop app to remind remote workers to stretch every 30 minutes and suggest exercises.\"\n",
    "\n",
    "TIPSC Review:\n",
    "Timely: The post-pandemic remote work trend is stabilizing. (Score: 3)\n",
    "Important: Mildly useful but low perceived urgency. (Score: 3)\n",
    "Profitable: Free alternatives exist; monetization unclear. (Score: 2)\n",
    "Solvable: Technically simple; easy to build. (Score: 5)\n",
    "Contextual: Team has coding skills but lacks health/UX expertise. (Score: 3)\n",
    "\n",
    "Overall Assessment: Fair (60%)\n",
    "Brief Justification: Simple, achievable idea with limited novelty and unclear market traction; \n",
    "lacks compelling urgency or differentiator.\n",
    "\n",
    "Example 4 - \n",
    "Pitch Statement:\n",
    "\"An app that plays motivational quotes every hour to keep users positive.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: No clear trend or urgency for hourly motivational quotes. (Score: 2)\n",
    "Important: Trivial problem with low impact. (Score: 2)\n",
    "Profitable: Difficult to monetize; saturated with free apps. (Score: 1)\n",
    "Solvable: Technically easy but adds little value. (Score: 4)\n",
    "Contextual: Team lacks psychological or design expertise. (Score: 2)\n",
    "\n",
    "Overall Assessment: Poor (40%)\n",
    "Brief Justification: While easily implementable, the idea solves no pressing problem, \n",
    "lacks clear market differentiation, and shows weak contextual relevance.\n",
    "\n",
    "Example 5 -\n",
    "Pitch Statement:\n",
    "\"A low-cost smart inhaler system that tracks asthma medication usage, predicts attacks using environmental data, \n",
    "and alerts caregivers in real time.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: Asthma rates are increasing due to urban pollution; immediate relevance. (Score: 5)\n",
    "Important: Critical for patients, families, and healthcare providers. (Score: 5)\n",
    "Profitable: Strong potential for insurance tie-ins and health partnerships. (Score: 4)\n",
    "Solvable: Current IoT + predictive AI make this feasible. (Score: 5)\n",
    "Contextual: Team has biomedical and data analytics background. (Score: 5)\n",
    "\n",
    "Overall Assessment: Excellent (95%)\n",
    "Brief Justification: Urgent and impactful healthcare problem with a clear path to implementation and adoption; \n",
    "strong interdisciplinary team fit enhances feasibility and trust.\n",
    "\n",
    "Example 6 - \n",
    "Pitch Statement:\n",
    "\"An AI chatbot that suggests eco-friendly alternatives when users shop online — like showing sustainable brands or \n",
    "second-hand options.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: Sustainability awareness is increasing but not yet mainstream behavior. (Score: 4)\n",
    "Important: Appeals to a growing but niche eco-conscious segment. (Score: 4)\n",
    "Profitable: Monetization possible via affiliate or brand partnerships. (Score: 4)\n",
    "Solvable: Readily achievable using APIs and recommendation engines. (Score: 5)\n",
    "Contextual: Team has AI experience but limited marketing background. (Score: 3)\n",
    "\n",
    "Overall Assessment: Good (80%)\n",
    "Brief Justification: Strong alignment with sustainability trends and implementable tech; \n",
    "moderate commercial potential limited by user behavior change barriers.\n",
    "\n",
    "Example 7 -\n",
    "Pitch Statement:\n",
    "\"A mobile app that helps people organize their daily to-do lists using colorful emojis and sound alerts to make productivity fun.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: Productivity apps remain evergreen but oversaturated. (Score: 3)\n",
    "Important: Low differentiation; helps individuals but no major impact. (Score: 3)\n",
    "Profitable: Hard to stand out in a crowded, free-app market. (Score: 2)\n",
    "Solvable: Simple app; easily buildable with existing frameworks. (Score: 5)\n",
    "Contextual: Team has beginner-level coding skills; limited UX experience. (Score: 3)\n",
    "\n",
    "Overall Assessment: Fair (60%)\n",
    "Brief Justification: Technically achievable but lacks novelty, urgency, and clear market pull; \n",
    "execution quality will determine limited success.\n",
    "\n",
    "Example 8 -\n",
    "Pitch Statement:\n",
    "\"An app that changes your phone wallpaper every hour to keep you inspired and motivated throughout the day.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: No identifiable need or trend driving this idea. (Score: 2)\n",
    "Important: Minimal user impact; cosmetic value only. (Score: 2)\n",
    "Profitable: No clear revenue stream or differentiator. (Score: 1)\n",
    "Solvable: Very easy to build with existing APIs. (Score: 4)\n",
    "Contextual: Team lacks direction and product reasoning. (Score: 2)\n",
    "\n",
    "Overall Assessment: Poor (40%)\n",
    "Brief Justification: Technically trivial concept with no significant need, value proposition, \n",
    "or sustainable market advantage; fails to meet hackathon impact criteria.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307c3cd",
   "metadata": {},
   "source": [
    "### Problem Evidence and Validation (Weightage : 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cea2912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_prob_evidence_val(problem_statement_text) :\n",
    "    return f\"\"\"\n",
    "        You are an expert evaluator for university hackathon pitch decks. Your task is to assess the Problem Evidence & Validation based on the rubric below.\n",
    "\n",
    "        RUBRIC:\n",
    "        - Excellent (90-100%): 10+ interviews with diverse stakeholders; multiple direct quotes; clear quantification of time/money impact\n",
    "        - Good (70-89%): 5-9 interviews; some relevant quotes; basic quantification\n",
    "        - Fair (50-69%): 3-4 interviews; limited evidence; vague numbers\n",
    "        - Poor (0-49%): <3 interviews; no direct evidence; purely anecdotal\n",
    "\n",
    "        The Problem Evidence and Validation content to evaluate is here:  {problem_statement_text}\n",
    "\n",
    "        INSTRUCTIONS:\n",
    "        1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "        2. Provide a 2-3 sentence justification citing specific evidence (or lack thereof) from the pitch deck\n",
    "        3. Note the approximate number of interviews mentioned (if any)\n",
    "\n",
    "        OUTPUT FORMAT:\n",
    "        Category: [Excellent/Good/Fair/Poor]\n",
    "        Justification: [Your short 2-3 sentence reasoning]\n",
    "        Interview Count: [Number or \"Not specified\"]\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5359273",
   "metadata": {},
   "source": [
    "### Market Opportunity & Viability (Weightage : 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0bacd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_market_viability(market_opportunity_viability_text) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Market Opportunity & Viability \n",
    "      based on the rubric below.\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Clear TAM/SAM/SOM with credible sources; strong profitability argument; competitive gap identified\n",
    "      - Good (70-89%): Basic market sizing; some business potential; mentions competitors\n",
    "      - Fair (50-69%): Vague market references; unclear business model\n",
    "      - Poor (0-49%): No market analysis; no commercial viability\n",
    "\n",
    "      The Market Opportunity and Viability content to evaluate is here: {market_opportunity_viability_text}\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification focusing on:\n",
    "         - Quality of market sizing (TAM/SAM/SOM presence and credibility)\n",
    "         - Business model clarity\n",
    "         - Competitive analysis depth\n",
    "      3. Note if credible sources are cited for market data\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your short 2-3 sentence reasoning]\n",
    "      Market Data Quality: [Strong/Moderate/Weak/Absent]\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9389c1",
   "metadata": {},
   "source": [
    "### TIPSC (Weightage : 15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ddf7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_tipsc(tipsc_text) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Problem Significance using \n",
    "      the TIPSC framework. \n",
    "      TIPSC means the following:\n",
    "      T = Timely = Is the problem curent and in need of an urgent solution or recently emergent and a solution can wait?\n",
    "      I = Important = Does the solution or solving this problem matter to a large or key group of customers or market sectors/segments?\n",
    "      P = Profitable = Will solving this problem yield Revenue or Value or a potential for these exist (even if limited)?\n",
    "      S = Solvable = Is it possible to create a solution for this problem now given the technology and other required resources?\n",
    "      C = Contextual = Is the current situation like team, policiefs, company, approach the right fit?\n",
    "\n",
    "      Here are a few examples of how to evaluate or assess TIPSC: \n",
    "      {TIPSC_FEW_SHOT_EXAMPLES}\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Compelling urgency + major impact + clear team advantage + realistic solution path\n",
    "      - Good (70-89%): Some timeliness + moderate impact + reasonable team fit\n",
    "      - Fair (50-69%): Vague timing + minor impact + generic team fit\n",
    "      - Poor (0-49%): No urgency + trivial problem + poor team fit\n",
    "\n",
    "      The TIPSC Content to be evaluated is: {tipsc_text}\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification addressing:\n",
    "         - Timeliness/urgency of the problem\n",
    "         - Scale and severity of impact\n",
    "         - Team's relevant advantage or expertise\n",
    "         - Realism of proposed solution path\n",
    "      3. Identify the strongest and weakest TIPSC element\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your reasoning]\n",
    "      Strongest Element: [T/I/P/S/C]\n",
    "      Weakest Element: [T/I/P/S/C]\n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df31f8",
   "metadata": {},
   "source": [
    "### Solution Direction & Value Proposition (Weightage : 15%)\n",
    "### FOR RD SIR TO VERIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1172ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_solution(solution_value_prop) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Solution Direction & Value Proposition based on the rubric below.\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Clear solution hypothesis directly addressing gaps; strong unique value proposition\n",
    "      - Good (70-89%): Basic solution direction; addresses some gaps\n",
    "      - Fair (50-69%): Vague solution idea; weak value proposition\n",
    "      - Poor (0-49%): No clear solution direction; copies existing solutions\n",
    "\n",
    "      Solution Hypothesis of the Pitch Deck is here: {solution_value_prop}\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification focusing on:\n",
    "         - Strength of value proposition\n",
    "         - Real-world impact\n",
    "      3. Note the most significant presentation strength or weakness\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your reasoning]\n",
    "      Key Strength/Weakness: [Brief description]\n",
    "\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6fb758",
   "metadata": {},
   "source": [
    "### Presentation Comprehension (Weightage : 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5d4e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_pres_comp(presentation_cohesion) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Presentation & Cohesion based on the rubric below.\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Compelling narrative; logical flow; professional design; clear communication\n",
    "      - Good (70-89%): Mostly coherent; decent design; some gaps in logic\n",
    "      - Fair (50-69%): Disjointed arguments; basic design; confusing flow\n",
    "      - Poor (0-49%): Incoherent story; poor design; unclear messaging\n",
    "\n",
    "      Summary of the Pitch Deck is here: {presentation_cohesion}\n",
    "\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification focusing on:\n",
    "         - Narrative coherence and logical flow\n",
    "         - Clarity of communication\n",
    "         - Overall professional quality\n",
    "      3. Note the most significant presentation strength or weakness\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your reasoning]\n",
    "      Key Strength/Weakness: [Brief description]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66de31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_decks_df = pd.read_csv(\"../EvaluateStudentIdeas/pitch_decks_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c5be3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to replaces spaces with underscores\n",
    "for col in pitch_decks_df :\n",
    "    pitch_decks_df = pitch_decks_df.rename(columns={col : col.replace(' ', '_')})\n",
    "pitch_decks_df = pitch_decks_df.rename(columns={'Problem_Statement_(cleaned)' : 'Problem_Statement_Cleaned'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c2abc027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Statement</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opportunity_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Solution_Hypothesis</th>\n",
       "      <th>References</th>\n",
       "      <th>Problem_Statement_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquaSmart Innovations</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team - Team Name: A...</td>\n",
       "      <td>Slide 2: Evidence of Customer's Pain Point - K...</td>\n",
       "      <td>Slide 3: Quantifying the Problem - Market Size...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC - Timely: C...</td>\n",
       "      <td>Slide 5: Competitive Landscape &amp; The Gap - Cur...</td>\n",
       "      <td>Slide 6: Solution Hypothesis - Proposed Soluti...</td>\n",
       "      <td>Slide 7: Next Steps - Prototype testing in 500...</td>\n",
       "      <td>Core Problem Statement: Urban Water Conservati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team Team Name: Tri...</td>\n",
       "      <td>Slide 2: Evidence of Customer’s Pain Point R&amp;D...</td>\n",
       "      <td>Slide 3: Quantifying the Problem Market Size (...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC (The Strate...</td>\n",
       "      <td>Slide 5: The Competitive Landscape &amp; The Gap C...</td>\n",
       "      <td>Slide 6: The Solution Hypothesis (High-Level O...</td>\n",
       "      <td>Slide 7: Appendix, References &amp; Next Steps Our...</td>\n",
       "      <td>Core Problem Statement: Artisan Market Access ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgriSat Tech</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team - Team Name: A...</td>\n",
       "      <td>Slide 2: Evidence of Customer's Pain Point - K...</td>\n",
       "      <td>Slide 3: Quantifying the Problem - Market Size...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC - Timely: I...</td>\n",
       "      <td>Slide 5: Competitive Landscape &amp; The Gap - Cur...</td>\n",
       "      <td>Slide 6: Solution Hypothesis - Proposed Soluti...</td>\n",
       "      <td>Slide 7: Next Steps - Partner with ISRO for sa...</td>\n",
       "      <td>Core Problem Statement: Precision Agriculture ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RuralConnect</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team - Team Name: R...</td>\n",
       "      <td>Slide 2: Evidence of Customer's Pain Point - K...</td>\n",
       "      <td>Slide 3: Quantifying the Problem - Market Size...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC - Timely: D...</td>\n",
       "      <td>Slide 5: Competitive Landscape &amp; The Gap - Cur...</td>\n",
       "      <td>Slide 6: Solution Hypothesis - Proposed Soluti...</td>\n",
       "      <td>Slide 7: Next Steps - Pilot in 50 villages acr...</td>\n",
       "      <td>Core Problem Statement: - Last Mile Rural Conn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Team_Name  \\\n",
       "0                              AquaSmart Innovations   \n",
       "1  Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...   \n",
       "2                                       AgriSat Tech   \n",
       "3                                       RuralConnect   \n",
       "\n",
       "                                   Problem_Statement  \\\n",
       "0  Slide 1: The Problem & The Team - Team Name: A...   \n",
       "1  Slide 1: The Problem & The Team Team Name: Tri...   \n",
       "2  Slide 1: The Problem & The Team - Team Name: A...   \n",
       "3  Slide 1: The Problem & The Team - Team Name: R...   \n",
       "\n",
       "                                    Problem_Evidence  \\\n",
       "0  Slide 2: Evidence of Customer's Pain Point - K...   \n",
       "1  Slide 2: Evidence of Customer’s Pain Point R&D...   \n",
       "2  Slide 2: Evidence of Customer's Pain Point - K...   \n",
       "3  Slide 2: Evidence of Customer's Pain Point - K...   \n",
       "\n",
       "                        Market_Opportunity_Viability  \\\n",
       "0  Slide 3: Quantifying the Problem - Market Size...   \n",
       "1  Slide 3: Quantifying the Problem Market Size (...   \n",
       "2  Slide 3: Quantifying the Problem - Market Size...   \n",
       "3  Slide 3: Quantifying the Problem - Market Size...   \n",
       "\n",
       "                                               TIPSC  \\\n",
       "0  Slide 4: Why This Problem is TIPSC - Timely: C...   \n",
       "1  Slide 4: Why This Problem is TIPSC (The Strate...   \n",
       "2  Slide 4: Why This Problem is TIPSC - Timely: I...   \n",
       "3  Slide 4: Why This Problem is TIPSC - Timely: D...   \n",
       "\n",
       "                                         Competition  \\\n",
       "0  Slide 5: Competitive Landscape & The Gap - Cur...   \n",
       "1  Slide 5: The Competitive Landscape & The Gap C...   \n",
       "2  Slide 5: Competitive Landscape & The Gap - Cur...   \n",
       "3  Slide 5: Competitive Landscape & The Gap - Cur...   \n",
       "\n",
       "                                 Solution_Hypothesis  \\\n",
       "0  Slide 6: Solution Hypothesis - Proposed Soluti...   \n",
       "1  Slide 6: The Solution Hypothesis (High-Level O...   \n",
       "2  Slide 6: Solution Hypothesis - Proposed Soluti...   \n",
       "3  Slide 6: Solution Hypothesis - Proposed Soluti...   \n",
       "\n",
       "                                          References  \\\n",
       "0  Slide 7: Next Steps - Prototype testing in 500...   \n",
       "1  Slide 7: Appendix, References & Next Steps Our...   \n",
       "2  Slide 7: Next Steps - Partner with ISRO for sa...   \n",
       "3  Slide 7: Next Steps - Pilot in 50 villages acr...   \n",
       "\n",
       "                           Problem_Statement_Cleaned  \n",
       "0  Core Problem Statement: Urban Water Conservati...  \n",
       "1  Core Problem Statement: Artisan Market Access ...  \n",
       "2  Core Problem Statement: Precision Agriculture ...  \n",
       "3  Core Problem Statement: - Last Mile Rural Conn...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_decks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f48ae72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key = os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5027692",
   "metadata": {},
   "source": [
    "### LLM-evaluation of each idea while maintaining context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c5997fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_cols = ['Team_Name', 'Problem_Evidence', 'Market_Opp_Viability', 'TIPSC', 'Solution_Dir_Val_Prop', 'Pres_Cohesion', 'Final_Score']\n",
    "grade_df = pd.DataFrame(columns=grade_cols)\n",
    "\n",
    "token_cols = ['Team_Name', 'Candidate_Tokens', 'Thought_Tokens', 'Input_Tokens', 'Output_Tokens', 'Total_Tokens']\n",
    "token_df = pd.DataFrame(columns=token_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e1767427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_grade_counts(res, token_counts) :\n",
    "    '''Extract the word score (Excellent, Good, etc.) and token counts for a given response'''\n",
    "    word_score = res.text.split(\"Category:\")[1].split(\"\\n\")[0].strip()\n",
    "    \n",
    "    prompt_total = res.usage_metadata.prompt_token_count\n",
    "    cand_total = res.usage_metadata.candidates_token_count\n",
    "    thought_total = res.usage_metadata.thoughts_token_count\n",
    "\n",
    "    if not cand_total :\n",
    "        cand_total = 0\n",
    "    if not thought_total :\n",
    "        thought_total = 0\n",
    "    \n",
    "    token_counts[0] += prompt_total\n",
    "    token_counts[1] += cand_total\n",
    "    token_counts[2] += thought_total\n",
    "    \n",
    "    return word_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "830238f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\\nPlease retry in 40.168625791s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Evaluate Metric #5\u001b[39;00m\n\u001b[32m     41\u001b[39m presentation_cohesion = team.Problem_Statement_Cleaned\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m cohesion_res = \u001b[38;5;28;01mawait\u001b[39;00m chat.send_message(prompt_pres_comp(presentation_cohesion))\n\u001b[32m     43\u001b[39m cohesion_word_score = extract_grade_counts(cohesion_res, token_counts)\n\u001b[32m     44\u001b[39m grade_df.at[teamNum, \u001b[33m'\u001b[39m\u001b[33mPres_Cohesion\u001b[39m\u001b[33m'\u001b[39m] = cohesion_word_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/google/genai/chats.py:416\u001b[39m, in \u001b[36mAsyncChat.send_message\u001b[39m\u001b[34m(self, message, config)\u001b[39m\n\u001b[32m    411\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    412\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMessage must be a valid part type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes.PartUnion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes.PartUnionDict\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    414\u001b[39m   )\n\u001b[32m    415\u001b[39m input_content = t.t_content(message)\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules.generate_content(\n\u001b[32m    417\u001b[39m     model=\u001b[38;5;28mself\u001b[39m._model,\n\u001b[32m    418\u001b[39m     contents=\u001b[38;5;28mself\u001b[39m._curated_history + [input_content],  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    419\u001b[39m     config=config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._config,\n\u001b[32m    420\u001b[39m )\n\u001b[32m    421\u001b[39m model_output = (\n\u001b[32m    422\u001b[39m     [response.candidates[\u001b[32m0\u001b[39m].content]\n\u001b[32m    423\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.candidates \u001b[38;5;129;01mand\u001b[39;00m response.candidates[\u001b[32m0\u001b[39m].content\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    425\u001b[39m )\n\u001b[32m    426\u001b[39m automatic_function_calling_history = (\n\u001b[32m    427\u001b[39m     response.automatic_function_calling_history\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.automatic_function_calling_history\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    430\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/google/genai/models.py:6727\u001b[39m, in \u001b[36mAsyncModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6725\u001b[39m response = types.GenerateContentResponse()\n\u001b[32m   6726\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m6727\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   6728\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   6729\u001b[39m   )\n\u001b[32m   6730\u001b[39m   remaining_remote_calls_afc -= \u001b[32m1\u001b[39m\n\u001b[32m   6731\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m remaining_remote_calls_afc == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/google/genai/models.py:5562\u001b[39m, in \u001b[36mAsyncModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5559\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   5560\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5562\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.async_request(\n\u001b[32m   5563\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, path, request_dict, http_options\n\u001b[32m   5564\u001b[39m )\n\u001b[32m   5566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   5567\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5568\u001b[39m ):\n\u001b[32m   5569\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/google/genai/_api_client.py:1326\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_request\u001b[39m(\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1317\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1320\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1321\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1322\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1323\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1324\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m   result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1327\u001b[39m       http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1328\u001b[39m   )\n\u001b[32m   1329\u001b[39m   response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1330\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=result.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/google/genai/_api_client.py:1271\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1269\u001b[39m     retry = tenacity.AsyncRetrying(**retry_kwargs)\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1273\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/tenacity/_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/google/genai/_api_client.py:1251\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1243\u001b[39m   \u001b[38;5;66;03m# aiohttp is not available. Fall back to httpx.\u001b[39;00m\n\u001b[32m   1244\u001b[39m   client_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_httpx_client.request(\n\u001b[32m   1245\u001b[39m       method=http_request.method,\n\u001b[32m   1246\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1249\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1250\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(client_response)\n\u001b[32m   1252\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(client_response.headers, [client_response.text])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CIESpark/CIEVenv/lib/python3.12/site-packages/google/genai/errors.py:166\u001b[39m, in \u001b[36mAPIError.raise_for_async_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\\nPlease retry in 40.168625791s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}"
     ]
    }
   ],
   "source": [
    "# Iterate over every team's submission\n",
    "# split, strip is to take content excluding \"Slide <num>\"\n",
    "for teamNum, team in enumerate(pitch_decks_df.itertuples()):\n",
    "    grade_df.at[teamNum, 'Team_Name'] = team.Team_Name\n",
    "    token_df.at[teamNum, 'Team_Name'] = team.Team_Name\n",
    "    prompt_total, cand_total, thought_total = 0, 0, 0\n",
    "    token_counts = [prompt_total, cand_total, thought_total]\n",
    "\n",
    "    chat = client.aio.chats.create(model='gemini-2.5-flash-preview-09-2025')\n",
    "    \n",
    "    # Evalute Metric #1\n",
    "    # Set problem_statement_text based on slides 1 & 2\n",
    "    ps_raw = \"Core Problem Statement: \" + team.Problem_Statement.split(\"Core Problem Statement:\", 1)[1].strip() + \"\\n\"\n",
    "    ps_evidence = team.Problem_Evidence.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    problem_statement_text = ps_raw + ps_evidence\n",
    "\n",
    "    PE_res = await chat.send_message(prompt_prob_evidence_val(problem_statement_text))\n",
    "    PE_word_score = extract_grade_counts(PE_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Problem_Evidence'] = PE_word_score\n",
    "\n",
    "\n",
    "    # Evaluate Metric #2\n",
    "    market_opportunity_viability_text = team.Market_Opportunity_Viability.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    MOV_res = await chat.send_message(prompt_market_viability(market_opportunity_viability_text))\n",
    "    MOV_word_score = extract_grade_counts(MOV_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Market_Opp_Viability'] = MOV_word_score\n",
    "\n",
    "    # Evaluate Metric #3\n",
    "    tipsc_text = \"Timely: \" + team.TIPSC.split(\"Timely\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    TIPSC_res = await chat.send_message(prompt_tipsc(tipsc_text))\n",
    "    TIPSC_word_score = extract_grade_counts(TIPSC_res, token_counts)\n",
    "    grade_df.at[teamNum, 'TIPSC'] = TIPSC_word_score\n",
    "\n",
    "    # Evaluate Metric #4 - REMOVE REDUNDANT WORDS HERE.\n",
    "    solution_value_prop = team.Solution_Hypothesis.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    sol_res = await chat.send_message(prompt_solution(solution_value_prop))\n",
    "    sol_word_score = extract_grade_counts(sol_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Solution_Dir_Val_Prop'] = sol_word_score\n",
    "\n",
    "    # Evaluate Metric #5\n",
    "    presentation_cohesion = team.Problem_Statement_Cleaned\n",
    "    cohesion_res = await chat.send_message(prompt_pres_comp(presentation_cohesion))\n",
    "    cohesion_word_score = extract_grade_counts(cohesion_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Pres_Cohesion'] = cohesion_word_score\n",
    "\n",
    "    # Token stats for this pitch\n",
    "    token_df.at[teamNum, 'Input_Tokens'] = token_counts[0]\n",
    "    token_df.at[teamNum, 'Candidate_Tokens'] = token_counts[1]\n",
    "    token_df.at[teamNum, 'Thought_Tokens'] = token_counts[2]\n",
    "    token_df.at[teamNum, 'Output_Tokens'] = token_counts[1] + token_counts[2]\n",
    "    token_df.at[teamNum, 'Total_Tokens'] = sum(token_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd1226a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opp_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Solution_Dir_Val_Prop</th>\n",
       "      <th>Pres_Cohesion</th>\n",
       "      <th>Final_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquaSmart Innovations</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Good</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Good</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Team_Name Problem_Evidence  \\\n",
       "0                              AquaSmart Innovations             Fair   \n",
       "1  Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...        Excellent   \n",
       "\n",
       "  Market_Opp_Viability      TIPSC Solution_Dir_Val_Prop Pres_Cohesion  \\\n",
       "0                 Good  Excellent             Excellent          Good   \n",
       "1                 Good  Excellent             Excellent           NaN   \n",
       "\n",
       "  Final_Score  \n",
       "0         NaN  \n",
       "1         NaN  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6c427c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opp_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Solution_Dir_Val_Prop</th>\n",
       "      <th>Pres_Cohesion</th>\n",
       "      <th>Final_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquaSmart Innovations</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Good</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Team_Name Problem_Evidence Market_Opp_Viability      TIPSC  \\\n",
       "0  AquaSmart Innovations             Fair                 Good  Excellent   \n",
       "\n",
       "  Solution_Dir_Val_Prop Pres_Cohesion Final_Score  \n",
       "0             Excellent          Good        0.75  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df = grade_df.drop(grade_df.index[1])\n",
    "grade_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d9fdb",
   "metadata": {},
   "source": [
    "### Get final scores for each idea using weightages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2eaa432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Score to Decimal Score mapping\n",
    "score_map = {'Poor' : 0.25,\n",
    "             'Fair' : 0.5,\n",
    "             'Good' : 0.75,\n",
    "             'Excellent' : 1\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ba81859",
   "metadata": {},
   "outputs": [],
   "source": [
    "for teamNum, team in enumerate(grade_df.itertuples()) :\n",
    "    grade_df.at[teamNum, 'Final_Score'] = 0.3 * score_map[team.Problem_Evidence] + \\\n",
    "                                        0.2 * score_map[team.Market_Opp_Viability] + \\\n",
    "                                        0.15 * score_map[team.TIPSC] + \\\n",
    "                                        0.15 * score_map[team.Solution_Dir_Val_Prop] + \\\n",
    "                                        0.2 * score_map[team.Pres_Cohesion]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d31f488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opp_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Solution_Dir_Val_Prop</th>\n",
       "      <th>Pres_Cohesion</th>\n",
       "      <th>Final_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquaSmart Innovations</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Good</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Team_Name Problem_Evidence Market_Opp_Viability      TIPSC  \\\n",
       "0  AquaSmart Innovations             Fair                 Good  Excellent   \n",
       "\n",
       "  Solution_Dir_Val_Prop Pres_Cohesion Final_Score  \n",
       "0             Excellent          Good        0.75  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIEVenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
