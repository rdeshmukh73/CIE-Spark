{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f568c68",
   "metadata": {},
   "source": [
    "### Multi-turn chat evaluation for every pitch deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6557df43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai import chats\n",
    "import time\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43681a29",
   "metadata": {},
   "source": [
    "### TIPSC Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb402024",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIPSC_FEW_SHOT_EXAMPLES = f\"\"\"\n",
    "Example 1 - \n",
    "Pitch Statement:\n",
    "\"An AI-powered tool that detects early signs of diabetic foot ulcers using smartphone images, helping rural healthcare \n",
    "workers intervene before complications arise.\"\n",
    "\n",
    "TIPSC Review:\n",
    "Timely: Rising diabetes cases in rural areas make early detection critical. (Score: 5)\n",
    "Important: Addresses a major healthcare gap affecting millions. (Score: 5)\n",
    "Profitable: Strong market through health-tech startups and public health programs. (Score: 4)\n",
    "Solvable: Feasible with current AI imaging and mobile tech. (Score: 5)\n",
    "Contextual: Team has medical + AI expertise with NGO partnerships. (Score: 5)\n",
    "\n",
    "Overall Assessment: Excellent (95%)\n",
    "Brief Justification: The problem is urgent, large-scale, and solvable with current technology. \n",
    "The team’s alignment with healthcare stakeholders strengthens contextual fit and market potential.\n",
    "\n",
    "Example 2 -\n",
    "Pitch Statement:\n",
    "\"A wearable hydration tracker that reminds users to drink water based on real-time sweat analysis and weather conditions.\"\n",
    "\n",
    "TIPSC Review:\n",
    "Timely: Wellness tech is growing, though hydration-specific solutions are not urgent. (Score: 4)\n",
    "Important: Moderate market among fitness and sports users. (Score: 4)\n",
    "Profitable: Viable as a premium product but niche appeal. (Score: 4)\n",
    "Solvable: Current sensors and IoT make it achievable. (Score: 5)\n",
    "Contextual: Team has IoT experience but limited market understanding. (Score: 3)\n",
    "\n",
    "Overall Assessment: Good (80%)\n",
    "Brief Justification: A relevant and buildable solution with moderate market potential; success depends on positioning \n",
    "and user adoption beyond enthusiasts.\n",
    "\n",
    "Example 3 - \n",
    "Pitch Statement:\n",
    "\"A desktop app to remind remote workers to stretch every 30 minutes and suggest exercises.\"\n",
    "\n",
    "TIPSC Review:\n",
    "Timely: The post-pandemic remote work trend is stabilizing. (Score: 3)\n",
    "Important: Mildly useful but low perceived urgency. (Score: 3)\n",
    "Profitable: Free alternatives exist; monetization unclear. (Score: 2)\n",
    "Solvable: Technically simple; easy to build. (Score: 5)\n",
    "Contextual: Team has coding skills but lacks health/UX expertise. (Score: 3)\n",
    "\n",
    "Overall Assessment: Fair (60%)\n",
    "Brief Justification: Simple, achievable idea with limited novelty and unclear market traction; \n",
    "lacks compelling urgency or differentiator.\n",
    "\n",
    "Example 4 - \n",
    "Pitch Statement:\n",
    "\"An app that plays motivational quotes every hour to keep users positive.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: No clear trend or urgency for hourly motivational quotes. (Score: 2)\n",
    "Important: Trivial problem with low impact. (Score: 2)\n",
    "Profitable: Difficult to monetize; saturated with free apps. (Score: 1)\n",
    "Solvable: Technically easy but adds little value. (Score: 4)\n",
    "Contextual: Team lacks psychological or design expertise. (Score: 2)\n",
    "\n",
    "Overall Assessment: Poor (40%)\n",
    "Brief Justification: While easily implementable, the idea solves no pressing problem, \n",
    "lacks clear market differentiation, and shows weak contextual relevance.\n",
    "\n",
    "Example 5 -\n",
    "Pitch Statement:\n",
    "\"A low-cost smart inhaler system that tracks asthma medication usage, predicts attacks using environmental data, \n",
    "and alerts caregivers in real time.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: Asthma rates are increasing due to urban pollution; immediate relevance. (Score: 5)\n",
    "Important: Critical for patients, families, and healthcare providers. (Score: 5)\n",
    "Profitable: Strong potential for insurance tie-ins and health partnerships. (Score: 4)\n",
    "Solvable: Current IoT + predictive AI make this feasible. (Score: 5)\n",
    "Contextual: Team has biomedical and data analytics background. (Score: 5)\n",
    "\n",
    "Overall Assessment: Excellent (95%)\n",
    "Brief Justification: Urgent and impactful healthcare problem with a clear path to implementation and adoption; \n",
    "strong interdisciplinary team fit enhances feasibility and trust.\n",
    "\n",
    "Example 6 - \n",
    "Pitch Statement:\n",
    "\"An AI chatbot that suggests eco-friendly alternatives when users shop online — like showing sustainable brands or \n",
    "second-hand options.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: Sustainability awareness is increasing but not yet mainstream behavior. (Score: 4)\n",
    "Important: Appeals to a growing but niche eco-conscious segment. (Score: 4)\n",
    "Profitable: Monetization possible via affiliate or brand partnerships. (Score: 4)\n",
    "Solvable: Readily achievable using APIs and recommendation engines. (Score: 5)\n",
    "Contextual: Team has AI experience but limited marketing background. (Score: 3)\n",
    "\n",
    "Overall Assessment: Good (80%)\n",
    "Brief Justification: Strong alignment with sustainability trends and implementable tech; \n",
    "moderate commercial potential limited by user behavior change barriers.\n",
    "\n",
    "Example 7 -\n",
    "Pitch Statement:\n",
    "\"A mobile app that helps people organize their daily to-do lists using colorful emojis and sound alerts to make productivity fun.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: Productivity apps remain evergreen but oversaturated. (Score: 3)\n",
    "Important: Low differentiation; helps individuals but no major impact. (Score: 3)\n",
    "Profitable: Hard to stand out in a crowded, free-app market. (Score: 2)\n",
    "Solvable: Simple app; easily buildable with existing frameworks. (Score: 5)\n",
    "Contextual: Team has beginner-level coding skills; limited UX experience. (Score: 3)\n",
    "\n",
    "Overall Assessment: Fair (60%)\n",
    "Brief Justification: Technically achievable but lacks novelty, urgency, and clear market pull; \n",
    "execution quality will determine limited success.\n",
    "\n",
    "Example 8 -\n",
    "Pitch Statement:\n",
    "\"An app that changes your phone wallpaper every hour to keep you inspired and motivated throughout the day.\"\n",
    "\n",
    "TIPSC Review:\n",
    "\n",
    "Timely: No identifiable need or trend driving this idea. (Score: 2)\n",
    "Important: Minimal user impact; cosmetic value only. (Score: 2)\n",
    "Profitable: No clear revenue stream or differentiator. (Score: 1)\n",
    "Solvable: Very easy to build with existing APIs. (Score: 4)\n",
    "Contextual: Team lacks direction and product reasoning. (Score: 2)\n",
    "\n",
    "Overall Assessment: Poor (40%)\n",
    "Brief Justification: Technically trivial concept with no significant need, value proposition, \n",
    "or sustainable market advantage; fails to meet hackathon impact criteria.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307c3cd",
   "metadata": {},
   "source": [
    "### Problem Evidence and Validation (Weightage : 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cea2912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_prob_evidence_val(problem_statement_text) :\n",
    "    return f\"\"\"\n",
    "        You are an expert evaluator for university hackathon pitch decks. Your task is to assess the Problem Evidence & Validation based on the rubric below.\n",
    "\n",
    "        RUBRIC:\n",
    "        - Excellent (90-100%): 10+ interviews with diverse stakeholders; multiple direct quotes; clear quantification of time/money impact\n",
    "        - Good (70-89%): 5-9 interviews; some relevant quotes; basic quantification\n",
    "        - Fair (50-69%): 3-4 interviews; limited evidence; vague numbers\n",
    "        - Poor (0-49%): <3 interviews; no direct evidence; purely anecdotal\n",
    "\n",
    "        The Problem Evidence and Validation content to evaluate is here:  {problem_statement_text}\n",
    "\n",
    "        INSTRUCTIONS:\n",
    "        1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "        2. Provide a 2-3 sentence justification citing specific evidence (or lack thereof) from the pitch deck\n",
    "        3. Note the approximate number of interviews mentioned (if any)\n",
    "\n",
    "        OUTPUT FORMAT:\n",
    "        Category: [Excellent/Good/Fair/Poor]\n",
    "        Justification: [Your short 2-3 sentence reasoning]\n",
    "        Interview Count: [Number or \"Not specified\"]\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5359273",
   "metadata": {},
   "source": [
    "### Market Opportunity & Viability (Weightage : 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bacd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_market_viability(market_opportunity_viability_text) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Market Opportunity & Viability \n",
    "      based on the rubric below.\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Clear TAM/SAM/SOM with credible sources; strong profitability argument; competitive gap identified\n",
    "      - Good (70-89%): Basic market sizing; some business potential; mentions competitors\n",
    "      - Fair (50-69%): Vague market references; unclear business model\n",
    "      - Poor (0-49%): No market analysis; no commercial viability\n",
    "\n",
    "      The Market Opportunity and Viability content to evaluate is here: {market_opportunity_viability_text}\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification focusing on:\n",
    "         - Quality of market sizing (TAM/SAM/SOM presence and credibility)\n",
    "         - Business model clarity\n",
    "         - Competitive analysis depth\n",
    "      3. Note if credible sources are cited for market data\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your short 2-3 sentence reasoning]\n",
    "      Market Data Quality: [Strong/Moderate/Weak/Absent]\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9389c1",
   "metadata": {},
   "source": [
    "### TIPSC (Weightage : 15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ddf7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_tipsc(tipsc_text) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Problem Significance using \n",
    "      the TIPSC framework. \n",
    "      TIPSC means the following:\n",
    "      T = Timely = Is the problem curent and in need of an urgent solution or recently emergent and a solution can wait?\n",
    "      I = Important = Does the solution or solving this problem matter to a large or key group of customers or market sectors/segments?\n",
    "      P = Profitable = Will solving this problem yield Revenue or Value or a potential for these exist (even if limited)?\n",
    "      S = Solvable = Is it possible to create a solution for this problem now given the technology and other required resources?\n",
    "      C = Contextual = Is the current situation like team, policiefs, company, approach the right fit?\n",
    "\n",
    "      Here are a few examples of how to evaluate or assess TIPSC: \n",
    "      {TIPSC_FEW_SHOT_EXAMPLES}\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Compelling urgency + major impact + clear team advantage + realistic solution path\n",
    "      - Good (70-89%): Some timeliness + moderate impact + reasonable team fit\n",
    "      - Fair (50-69%): Vague timing + minor impact + generic team fit\n",
    "      - Poor (0-49%): No urgency + trivial problem + poor team fit\n",
    "\n",
    "      The TIPSC Content to be evaluated is: {tipsc_text}\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification addressing:\n",
    "         - Timeliness/urgency of the problem\n",
    "         - Scale and severity of impact\n",
    "         - Team's relevant advantage or expertise\n",
    "         - Realism of proposed solution path\n",
    "      3. Identify the strongest and weakest TIPSC element\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your reasoning]\n",
    "      Strongest Element: [T/I/P/S/C]\n",
    "      Weakest Element: [T/I/P/S/C]\n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df31f8",
   "metadata": {},
   "source": [
    "### Solution Direction & Value Proposition (Weightage : 15%)\n",
    "### FOR RD SIR TO VERIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1172ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_solution(solution_value_prop) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Solution Direction & Value Proposition based on the rubric below.\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Clear solution hypothesis directly addressing gaps; strong unique value proposition\n",
    "      - Good (70-89%): Basic solution direction; addresses some gaps\n",
    "      - Fair (50-69%): Vague solution idea; weak value proposition\n",
    "      - Poor (0-49%): No clear solution direction; copies existing solutions\n",
    "\n",
    "      Solution Hypothesis of the Pitch Deck is here: {solution_value_prop}\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification focusing on:\n",
    "         - Strength of value proposition\n",
    "         - Real-world impact\n",
    "      3. Note the most significant presentation strength or weakness\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your reasoning]\n",
    "      Key Strength/Weakness: [Brief description]\n",
    "\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6fb758",
   "metadata": {},
   "source": [
    "### Presentation Comprehension (Weightage : 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5d4e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_pres_comp(presentation_cohesion) :\n",
    "   return f\"\"\"\n",
    "      You are an expert evaluator for university hackathon pitch decks. Your task is to assess Presentation & Cohesion based on the rubric below.\n",
    "\n",
    "      RUBRIC:\n",
    "      - Excellent (90-100%): Compelling narrative; logical flow; professional design; clear communication\n",
    "      - Good (70-89%): Mostly coherent; decent design; some gaps in logic\n",
    "      - Fair (50-69%): Disjointed arguments; basic design; confusing flow\n",
    "      - Poor (0-49%): Incoherent story; poor design; unclear messaging\n",
    "\n",
    "      Summary of the Pitch Deck is here: {presentation_cohesion}\n",
    "\n",
    "\n",
    "      INSTRUCTIONS:\n",
    "      1. Assign ONE category: Excellent, Good, Fair, or Poor\n",
    "      2. Provide a 2-3 sentence justification focusing on:\n",
    "         - Narrative coherence and logical flow\n",
    "         - Clarity of communication\n",
    "         - Overall professional quality\n",
    "      3. Note the most significant presentation strength or weakness\n",
    "\n",
    "      OUTPUT FORMAT:\n",
    "      Category: [Excellent/Good/Fair/Poor]\n",
    "      Justification: [Your reasoning]\n",
    "      Key Strength/Weakness: [Brief description]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66de31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_decks_df = pd.read_csv(\"../EvaluateStudentIdeas/pitch_decks_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c5be3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to replaces spaces with underscores\n",
    "for col in pitch_decks_df :\n",
    "    pitch_decks_df = pitch_decks_df.rename(columns={col : col.replace(' ', '_')})\n",
    "pitch_decks_df = pitch_decks_df.rename(columns={'Problem_Statement_(cleaned)' : 'Problem_Statement_Cleaned'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2abc027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Statement</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opportunity_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Solution_Hypothesis</th>\n",
       "      <th>References</th>\n",
       "      <th>Problem_Statement_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquaSmart Innovations</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team - Team Name: A...</td>\n",
       "      <td>Slide 2: Evidence of Customer's Pain Point - K...</td>\n",
       "      <td>Slide 3: Quantifying the Problem - Market Size...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC - Timely: C...</td>\n",
       "      <td>Slide 5: Competitive Landscape &amp; The Gap - Cur...</td>\n",
       "      <td>Slide 6: Solution Hypothesis - Proposed Soluti...</td>\n",
       "      <td>Slide 7: Next Steps - Prototype testing in 500...</td>\n",
       "      <td>Core Problem Statement: Urban Water Conservati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team Team Name: Tri...</td>\n",
       "      <td>Slide 2: Evidence of Customer’s Pain Point R&amp;D...</td>\n",
       "      <td>Slide 3: Quantifying the Problem Market Size (...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC (The Strate...</td>\n",
       "      <td>Slide 5: The Competitive Landscape &amp; The Gap C...</td>\n",
       "      <td>Slide 6: The Solution Hypothesis (High-Level O...</td>\n",
       "      <td>Slide 7: Appendix, References &amp; Next Steps Our...</td>\n",
       "      <td>Core Problem Statement: Artisan Market Access ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgriSat Tech</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team - Team Name: A...</td>\n",
       "      <td>Slide 2: Evidence of Customer's Pain Point - K...</td>\n",
       "      <td>Slide 3: Quantifying the Problem - Market Size...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC - Timely: I...</td>\n",
       "      <td>Slide 5: Competitive Landscape &amp; The Gap - Cur...</td>\n",
       "      <td>Slide 6: Solution Hypothesis - Proposed Soluti...</td>\n",
       "      <td>Slide 7: Next Steps - Partner with ISRO for sa...</td>\n",
       "      <td>Core Problem Statement: Precision Agriculture ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RuralConnect</td>\n",
       "      <td>Slide 1: The Problem &amp; The Team - Team Name: R...</td>\n",
       "      <td>Slide 2: Evidence of Customer's Pain Point - K...</td>\n",
       "      <td>Slide 3: Quantifying the Problem - Market Size...</td>\n",
       "      <td>Slide 4: Why This Problem is TIPSC - Timely: D...</td>\n",
       "      <td>Slide 5: Competitive Landscape &amp; The Gap - Cur...</td>\n",
       "      <td>Slide 6: Solution Hypothesis - Proposed Soluti...</td>\n",
       "      <td>Slide 7: Next Steps - Pilot in 50 villages acr...</td>\n",
       "      <td>Core Problem Statement: - Last Mile Rural Conn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Team_Name  \\\n",
       "0                              AquaSmart Innovations   \n",
       "1  Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...   \n",
       "2                                       AgriSat Tech   \n",
       "3                                       RuralConnect   \n",
       "\n",
       "                                   Problem_Statement  \\\n",
       "0  Slide 1: The Problem & The Team - Team Name: A...   \n",
       "1  Slide 1: The Problem & The Team Team Name: Tri...   \n",
       "2  Slide 1: The Problem & The Team - Team Name: A...   \n",
       "3  Slide 1: The Problem & The Team - Team Name: R...   \n",
       "\n",
       "                                    Problem_Evidence  \\\n",
       "0  Slide 2: Evidence of Customer's Pain Point - K...   \n",
       "1  Slide 2: Evidence of Customer’s Pain Point R&D...   \n",
       "2  Slide 2: Evidence of Customer's Pain Point - K...   \n",
       "3  Slide 2: Evidence of Customer's Pain Point - K...   \n",
       "\n",
       "                        Market_Opportunity_Viability  \\\n",
       "0  Slide 3: Quantifying the Problem - Market Size...   \n",
       "1  Slide 3: Quantifying the Problem Market Size (...   \n",
       "2  Slide 3: Quantifying the Problem - Market Size...   \n",
       "3  Slide 3: Quantifying the Problem - Market Size...   \n",
       "\n",
       "                                               TIPSC  \\\n",
       "0  Slide 4: Why This Problem is TIPSC - Timely: C...   \n",
       "1  Slide 4: Why This Problem is TIPSC (The Strate...   \n",
       "2  Slide 4: Why This Problem is TIPSC - Timely: I...   \n",
       "3  Slide 4: Why This Problem is TIPSC - Timely: D...   \n",
       "\n",
       "                                         Competition  \\\n",
       "0  Slide 5: Competitive Landscape & The Gap - Cur...   \n",
       "1  Slide 5: The Competitive Landscape & The Gap C...   \n",
       "2  Slide 5: Competitive Landscape & The Gap - Cur...   \n",
       "3  Slide 5: Competitive Landscape & The Gap - Cur...   \n",
       "\n",
       "                                 Solution_Hypothesis  \\\n",
       "0  Slide 6: Solution Hypothesis - Proposed Soluti...   \n",
       "1  Slide 6: The Solution Hypothesis (High-Level O...   \n",
       "2  Slide 6: Solution Hypothesis - Proposed Soluti...   \n",
       "3  Slide 6: Solution Hypothesis - Proposed Soluti...   \n",
       "\n",
       "                                          References  \\\n",
       "0  Slide 7: Next Steps - Prototype testing in 500...   \n",
       "1  Slide 7: Appendix, References & Next Steps Our...   \n",
       "2  Slide 7: Next Steps - Partner with ISRO for sa...   \n",
       "3  Slide 7: Next Steps - Pilot in 50 villages acr...   \n",
       "\n",
       "                           Problem_Statement_Cleaned  \n",
       "0  Core Problem Statement: Urban Water Conservati...  \n",
       "1  Core Problem Statement: Artisan Market Access ...  \n",
       "2  Core Problem Statement: Precision Agriculture ...  \n",
       "3  Core Problem Statement: - Last Mile Rural Conn...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_decks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f48ae72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = genai.Client(api_key = os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5027692",
   "metadata": {},
   "source": [
    "### LLM-evaluation of each idea while maintaining context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5997fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_cols = ['Team_Name', 'Problem_Evidence', 'Market_Opp_Viability', 'TIPSC', 'Solution_Dir_Val_Prop', 'Pres_Cohesion', 'Final_Score']\n",
    "grade_df = pd.DataFrame(columns=grade_cols)\n",
    "\n",
    "token_cols = ['Team_Name', 'Candidate_Tokens', 'Thought_Tokens', 'Input_Tokens', 'Output_Tokens', 'Total_Tokens']\n",
    "token_df = pd.DataFrame(columns=token_cols)\n",
    "\n",
    "justif_cols = ['Team_Name', 'Problem_Evidence', 'Market_Opp_Viability', 'TIPSC', 'Solution_Dir_Val_Prop', 'Pres_Cohesion']\n",
    "justif_df = pd.DataFrame(columns=justif_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1767427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_grade_counts(res, token_counts) :\n",
    "    '''Extract the word score (Excellent, Good, etc.) and token counts for a given response'''\n",
    "    word_score = res.text.split(\"Category:\")[1].split(\"\\n\")[0].strip()\n",
    "    \n",
    "    prompt_total = res.usage_metadata.prompt_token_count\n",
    "    cand_total = res.usage_metadata.candidates_token_count\n",
    "    thought_total = res.usage_metadata.thoughts_token_count\n",
    "\n",
    "    if not cand_total :\n",
    "        cand_total = 0\n",
    "    if not thought_total :\n",
    "        thought_total = 0\n",
    "    \n",
    "    token_counts[0] += prompt_total\n",
    "    token_counts[1] += cand_total\n",
    "    token_counts[2] += thought_total\n",
    "    \n",
    "    return word_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "830238f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over every team's submission\n",
    "# # split, strip is to take content excluding \"Slide <num>\"\n",
    "# for teamNum, team in enumerate(pitch_decks_df.itertuples()):\n",
    "#     grade_df.at[teamNum, 'Team_Name'] = team.Team_Name\n",
    "#     token_df.at[teamNum, 'Team_Name'] = team.Team_Name\n",
    "#     prompt_total, cand_total, thought_total = 0, 0, 0\n",
    "#     token_counts = [prompt_total, cand_total, thought_total]\n",
    "    \n",
    "#     # Evalute Metric #1\n",
    "#     # Set problem_statement_text based on slides 1 & 2\n",
    "#     ps_raw = \"Core Problem Statement: \" + team.Problem_Statement.split(\"Core Problem Statement:\", 1)[1].strip() + \"\\n\"\n",
    "#     ps_evidence = team.Problem_Evidence.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "#     problem_statement_text = ps_raw + ps_evidence\n",
    "\n",
    "#     PE_res = await chat.send_message(prompt_prob_evidence_val(problem_statement_text))\n",
    "#     PE_word_score = extract_grade_counts(PE_res, token_counts)\n",
    "#     grade_df.at[teamNum, 'Problem_Evidence'] = PE_word_score\n",
    "\n",
    "\n",
    "#     # Evaluate Metric #2\n",
    "#     market_opportunity_viability_text = team.Market_Opportunity_Viability.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "#     MOV_res = await chat.send_message(prompt_market_viability(market_opportunity_viability_text))\n",
    "#     MOV_word_score = extract_grade_counts(MOV_res, token_counts)\n",
    "#     grade_df.at[teamNum, 'Market_Opp_Viability'] = MOV_word_score\n",
    "\n",
    "#     # Evaluate Metric #3\n",
    "#     tipsc_text = \"Timely: \" + team.TIPSC.split(\"Timely\", 1)[1].split(\":\", 1)[1].strip()\n",
    "#     TIPSC_res = await chat.send_message(prompt_tipsc(tipsc_text))\n",
    "#     TIPSC_word_score = extract_grade_counts(TIPSC_res, token_counts)\n",
    "#     grade_df.at[teamNum, 'TIPSC'] = TIPSC_word_score\n",
    "\n",
    "#     # Evaluate Metric #4 - REMOVE REDUNDANT WORDS HERE.\n",
    "#     solution_value_prop = team.Solution_Hypothesis.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "#     sol_res = await chat.send_message(prompt_solution(solution_value_prop))\n",
    "#     sol_word_score = extract_grade_counts(sol_res, token_counts)\n",
    "#     grade_df.at[teamNum, 'Solution_Dir_Val_Prop'] = sol_word_score\n",
    "\n",
    "#     # Evaluate Metric #5\n",
    "#     presentation_cohesion = team.Problem_Statement_Cleaned\n",
    "#     cohesion_res = await chat.send_message(prompt_pres_comp(presentation_cohesion))\n",
    "#     cohesion_word_score = extract_grade_counts(cohesion_res, token_counts)\n",
    "#     grade_df.at[teamNum, 'Pres_Cohesion'] = cohesion_word_score\n",
    "\n",
    "#     # Token stats for this pitch\n",
    "#     token_df.at[teamNum, 'Input_Tokens'] = token_counts[0]\n",
    "#     token_df.at[teamNum, 'Candidate_Tokens'] = token_counts[1]\n",
    "#     token_df.at[teamNum, 'Thought_Tokens'] = token_counts[2]\n",
    "#     token_df.at[teamNum, 'Output_Tokens'] = token_counts[1] + token_counts[2]\n",
    "#     token_df.at[teamNum, 'Total_Tokens'] = sum(token_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ac49d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Candidate_Tokens</th>\n",
       "      <th>Thought_Tokens</th>\n",
       "      <th>Input_Tokens</th>\n",
       "      <th>Output_Tokens</th>\n",
       "      <th>Total_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Team_Name, Candidate_Tokens, Thought_Tokens, Input_Tokens, Output_Tokens, Total_Tokens]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d9fdb",
   "metadata": {},
   "source": [
    "### Get final scores for each idea using weightages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2eaa432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Score to Decimal Score mapping\n",
    "score_map = {'Poor' : 0.25,\n",
    "             'Fair' : 0.5,\n",
    "             'Good' : 0.75,\n",
    "             'Excellent' : 1\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ba81859",
   "metadata": {},
   "outputs": [],
   "source": [
    "for teamNum, team in enumerate(grade_df.itertuples()) :\n",
    "    grade_df.at[teamNum, 'Final_Score'] = 0.3 * score_map[team.Problem_Evidence] + \\\n",
    "                                        0.2 * score_map[team.Market_Opp_Viability] + \\\n",
    "                                        0.15 * score_map[team.TIPSC] + \\\n",
    "                                        0.15 * score_map[team.Solution_Dir_Val_Prop] + \\\n",
    "                                        0.2 * score_map[team.Pres_Cohesion]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d31f488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opp_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Solution_Dir_Val_Prop</th>\n",
       "      <th>Pres_Cohesion</th>\n",
       "      <th>Final_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Team_Name, Problem_Evidence, Market_Opp_Viability, TIPSC, Solution_Dir_Val_Prop, Pres_Cohesion, Final_Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afb09d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Candidate_Tokens</th>\n",
       "      <th>Thought_Tokens</th>\n",
       "      <th>Input_Tokens</th>\n",
       "      <th>Output_Tokens</th>\n",
       "      <th>Total_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Team_Name, Candidate_Tokens, Thought_Tokens, Input_Tokens, Output_Tokens, Total_Tokens]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e40db7e",
   "metadata": {},
   "source": [
    "# Revised criteria\n",
    "1. Integer on scale of 1-10\n",
    "2. 2-3 line justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72513bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d37a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrompt(rubrik, text) :\n",
    "    return f\"\"\"\n",
    "            Rubrik: {rubrik}\n",
    "            Text: {text}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27afc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_score_justif(res, token_counts) :\n",
    "    num_score = res.text.split(\"Score:\")[1].split(\"\\n\")[0].strip()\n",
    "    justification = res.text.split(\"Justification:\")[1].strip()\n",
    "    \n",
    "    prompt_total = res.usage_metadata.prompt_token_count\n",
    "    cand_total = res.usage_metadata.candidates_token_count\n",
    "    thought_total = res.usage_metadata.thoughts_token_count\n",
    "\n",
    "    if not cand_total :\n",
    "        cand_total = 0\n",
    "    if not thought_total :\n",
    "        thought_total = 0\n",
    "    \n",
    "    token_counts[0] += prompt_total\n",
    "    token_counts[1] += cand_total\n",
    "    token_counts[2] += thought_total\n",
    "    \n",
    "    return int(num_score), justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ed34ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key = os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502856ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over every team's submission\n",
    "# split, strip is to take content excluding \"Slide <num>\"\n",
    "for teamNum, team in enumerate(pitch_decks_df.itertuples()):\n",
    "    grade_df.at[teamNum, 'Team_Name'] = team.Team_Name\n",
    "    token_df.at[teamNum, 'Team_Name'] = team.Team_Name\n",
    "    justif_df.at[teamNum, 'Team_Name'] = team.Team_Name\n",
    "    prompt_total, cand_total, thought_total = 0, 0, 0\n",
    "    token_counts = [prompt_total, cand_total, thought_total]\n",
    "\n",
    "    chat = client.aio.chats.create(\n",
    "        model='gemini-2.5-flash-preview-09-2025',\n",
    "        config = types.GenerateContentConfig(\n",
    "            system_instruction=\"\"\"\n",
    "                You are an expert evaluator for university hackathon pitch decks.\n",
    "                \n",
    "                Your task is rate different rubriks with an INTEGER on a scale of 1 to 10,\n",
    "                1 being the lowest and 10 the highest.\n",
    "\n",
    "                Use the following to evaluate the TIPSC rubrik :\n",
    "                T = Timely = Is the problem curent and in need of an urgent solution or recently emergent and a solution can wait?\n",
    "                I = Important = Does the solution or solving this problem matter to a large or key group of customers or market sectors/segments?\n",
    "                P = Profitable = Will solving this problem yield Revenue or Value or a potential for these exist (even if limited)?\n",
    "                S = Solvable = Is it possible to create a solution for this problem now given the technology and other required resources?\n",
    "                C = Contextual = Is the current situation like team, policiefs, company, approach the right fit?\n",
    "\n",
    "                Input Format :\n",
    "                - Rubrik:\n",
    "                - Text:\n",
    "\n",
    "                Output Format :\n",
    "                - Score:\n",
    "                - Justification: (In 2 lines)\n",
    "            \"\"\"\n",
    "        ))\n",
    "        \n",
    "    # Evalute Metric #1\n",
    "    # Set problem_statement_text based on slides 1 & 2\n",
    "    ps_raw = \"Core Problem Statement: \" + team.Problem_Statement.split(\"Core Problem Statement:\", 1)[1].strip() + \"\\n\"\n",
    "    ps_evidence = team.Problem_Evidence.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    problem_statement_text = ps_raw + ps_evidence\n",
    "\n",
    "    PE_res = await chat.send_message(getPrompt(rubrik='Problem Evidence & Validation', text=problem_statement_text))\n",
    "    time.sleep(2)\n",
    "    PE_num_score, justif = extract_num_score_justif(PE_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Problem_Evidence'] = PE_num_score\n",
    "    justif_df.at[teamNum, 'Problem_Evidence'] = justif\n",
    "\n",
    "\n",
    "    # Evaluate Metric #2\n",
    "    market_opportunity_viability_text = team.Market_Opportunity_Viability.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    MOV_res = await chat.send_message(getPrompt(rubrik='Market Opportunity & Viability', text=market_opportunity_viability_text))\n",
    "    time.sleep(2)\n",
    "    MOV_num_score, justif = extract_num_score_justif(MOV_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Market_Opp_Viability'] = MOV_num_score\n",
    "    justif_df.at[teamNum, 'Market_Opp_Viability'] = justif\n",
    "\n",
    "    # Evaluate Metric #3\n",
    "    tipsc_text = \"Timely: \" + team.TIPSC.split(\"Timely\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    TIPSC_res = await chat.send_message(getPrompt(rubrik='TIPSC', text=tipsc_text))\n",
    "    time.sleep(2)\n",
    "    TIPSC_num_score, justif = extract_num_score_justif(TIPSC_res, token_counts)\n",
    "    grade_df.at[teamNum, 'TIPSC'] = TIPSC_num_score\n",
    "    justif_df.at[teamNum, 'TIPSC'] = justif\n",
    "\n",
    "    # Evaluate Metric #4 - REMOVE REDUNDANT WORDS HERE.\n",
    "    solution_value_prop = team.Solution_Hypothesis.split(\"Slide\", 1)[1].split(\":\", 1)[1].strip()\n",
    "    sol_res = await chat.send_message(getPrompt(rubrik='Solution Direction & Value Proposition', text=solution_value_prop))\n",
    "    time.sleep(2)\n",
    "    sol_num_score, justif = extract_num_score_justif(sol_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Solution_Dir_Val_Prop'] = sol_num_score\n",
    "    justif_df.at[teamNum, 'Solution_Dir_Val_Prop'] = justif\n",
    "\n",
    "    # Evaluate Metric #5\n",
    "    presentation_cohesion = team.Problem_Statement_Cleaned\n",
    "    cohesion_res = await chat.send_message(getPrompt(rubrik='Presentation & Communication', text=presentation_cohesion))\n",
    "    time.sleep(2)\n",
    "    cohesion_num_score, justif = extract_num_score_justif(cohesion_res, token_counts)\n",
    "    grade_df.at[teamNum, 'Pres_Cohesion'] = cohesion_num_score\n",
    "    justif_df.at[teamNum, 'Pres_Cohesion'] = justif\n",
    "\n",
    "    # Token stats for this pitch\n",
    "    token_df.at[teamNum, 'Input_Tokens'] = token_counts[0]\n",
    "    token_df.at[teamNum, 'Candidate_Tokens'] = token_counts[1]\n",
    "    token_df.at[teamNum, 'Thought_Tokens'] = token_counts[2]\n",
    "    token_df.at[teamNum, 'Output_Tokens'] = token_counts[1] + token_counts[2]\n",
    "    token_df.at[teamNum, 'Total_Tokens'] = sum(token_counts)\n",
    "\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bcb16348",
   "metadata": {},
   "outputs": [],
   "source": [
    "for teamNum, team in enumerate(grade_df.itertuples()) :\n",
    "    grade_df.at[teamNum, 'Final_Score'] = 0.3 * team.Problem_Evidence + \\\n",
    "                                        0.2 * team.Market_Opp_Viability + \\\n",
    "                                        0.15 * team.TIPSC + \\\n",
    "                                        0.15 * team.Solution_Dir_Val_Prop + \\\n",
    "                                        0.2 * team.Pres_Cohesion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a1e4b",
   "metadata": {},
   "source": [
    "### Average input and output tokens calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14887e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'Avg_Input' : [token_df['Input_Tokens'].mean()],\n",
    "    'Avg_Output' : [token_df['Output_Tokens'].mean()],\n",
    "    'Avg_Total' : [token_df['Total_Tokens'].mean()],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e5e1df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens for all teams =  23340\n"
     ]
    }
   ],
   "source": [
    "print(\"Total tokens for all teams = \", token_df['Total_Tokens'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be3af77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Candidate_Tokens</th>\n",
       "      <th>Thought_Tokens</th>\n",
       "      <th>Input_Tokens</th>\n",
       "      <th>Output_Tokens</th>\n",
       "      <th>Total_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquaSmart Innovations</td>\n",
       "      <td>283</td>\n",
       "      <td>1382</td>\n",
       "      <td>3267</td>\n",
       "      <td>1665</td>\n",
       "      <td>4932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...</td>\n",
       "      <td>351</td>\n",
       "      <td>1544</td>\n",
       "      <td>6147</td>\n",
       "      <td>1895</td>\n",
       "      <td>8042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgriSat Tech</td>\n",
       "      <td>310</td>\n",
       "      <td>1961</td>\n",
       "      <td>3299</td>\n",
       "      <td>2271</td>\n",
       "      <td>5570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RuralConnect</td>\n",
       "      <td>289</td>\n",
       "      <td>1164</td>\n",
       "      <td>3343</td>\n",
       "      <td>1453</td>\n",
       "      <td>4796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Team_Name Candidate_Tokens  \\\n",
       "0                              AquaSmart Innovations              283   \n",
       "1  Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...              351   \n",
       "2                                       AgriSat Tech              310   \n",
       "3                                       RuralConnect              289   \n",
       "\n",
       "  Thought_Tokens Input_Tokens Output_Tokens Total_Tokens  \n",
       "0           1382         3267          1665         4932  \n",
       "1           1544         6147          1895         8042  \n",
       "2           1961         3299          2271         5570  \n",
       "3           1164         3343          1453         4796  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9953f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opp_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Solution_Dir_Val_Prop</th>\n",
       "      <th>Pres_Cohesion</th>\n",
       "      <th>Final_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquaSmart Innovations</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgriSat Tech</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RuralConnect</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Team_Name Problem_Evidence  \\\n",
       "0                              AquaSmart Innovations               10   \n",
       "1  Triad_Kernals_Problem_Deck_2025 - Inchara K Ku...               10   \n",
       "2                                       AgriSat Tech               10   \n",
       "3                                       RuralConnect                9   \n",
       "\n",
       "  Market_Opp_Viability TIPSC Solution_Dir_Val_Prop Pres_Cohesion Final_Score  \n",
       "0                    8    10                     9            10        9.45  \n",
       "1                    8     9                     9             9         9.1  \n",
       "2                    9     9                    10            10        9.65  \n",
       "3                    8     9                     7             9         8.5  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7841003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Input</th>\n",
       "      <th>Avg_Output</th>\n",
       "      <th>Avg_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4014.0</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>5835.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg_Input  Avg_Output  Avg_Total\n",
       "0     4014.0      1821.0     5835.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "272c19c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Problem_Evidence</th>\n",
       "      <th>Market_Opp_Viability</th>\n",
       "      <th>TIPSC</th>\n",
       "      <th>Solution_Dir_Val_Prop</th>\n",
       "      <th>Pres_Cohesion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The evidence is robust, quantifying the proble...</td>\n",
       "      <td>The market sizing (TAM, SAM, SOM) is well-defi...</td>\n",
       "      <td>All five criteria are maximally satisfied: the...</td>\n",
       "      <td>The solution is comprehensive, combining IoT h...</td>\n",
       "      <td>The communication is exceptionally clear, star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The team excelled by quantifying the annual in...</td>\n",
       "      <td>The market size (TAM/SAM/SOM) is clearly quant...</td>\n",
       "      <td>The pitch robustly validates T, I, and P with ...</td>\n",
       "      <td>The value proposition is clear, directly addre...</td>\n",
       "      <td>The core problem statement is immediately impa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The problem is robustly quantified with a mass...</td>\n",
       "      <td>The market sizing (TAM/SAM/SOM) is clearly def...</td>\n",
       "      <td>The proposal scores highly due to strong align...</td>\n",
       "      <td>The solution provides a holistic, multi-layere...</td>\n",
       "      <td>The communication is outstanding, immediately ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The problem is quantified effectively using bo...</td>\n",
       "      <td>The market sizing (TAM, SAM, SOM) is clearly d...</td>\n",
       "      <td>All TIPSC components are highly aligned, parti...</td>\n",
       "      <td>The solution uses relevant, distributed techno...</td>\n",
       "      <td>The communication is exceptionally clear, star...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team_Name                                   Problem_Evidence  \\\n",
       "0       NaN  The evidence is robust, quantifying the proble...   \n",
       "1       NaN  The team excelled by quantifying the annual in...   \n",
       "2       NaN  The problem is robustly quantified with a mass...   \n",
       "3       NaN  The problem is quantified effectively using bo...   \n",
       "\n",
       "                                Market_Opp_Viability  \\\n",
       "0  The market sizing (TAM, SAM, SOM) is well-defi...   \n",
       "1  The market size (TAM/SAM/SOM) is clearly quant...   \n",
       "2  The market sizing (TAM/SAM/SOM) is clearly def...   \n",
       "3  The market sizing (TAM, SAM, SOM) is clearly d...   \n",
       "\n",
       "                                               TIPSC  \\\n",
       "0  All five criteria are maximally satisfied: the...   \n",
       "1  The pitch robustly validates T, I, and P with ...   \n",
       "2  The proposal scores highly due to strong align...   \n",
       "3  All TIPSC components are highly aligned, parti...   \n",
       "\n",
       "                               Solution_Dir_Val_Prop  \\\n",
       "0  The solution is comprehensive, combining IoT h...   \n",
       "1  The value proposition is clear, directly addre...   \n",
       "2  The solution provides a holistic, multi-layere...   \n",
       "3  The solution uses relevant, distributed techno...   \n",
       "\n",
       "                                       Pres_Cohesion  \n",
       "0  The communication is exceptionally clear, star...  \n",
       "1  The core problem statement is immediately impa...  \n",
       "2  The communication is outstanding, immediately ...  \n",
       "3  The communication is exceptionally clear, star...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justif_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIEVenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
